{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "resident-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import spacy \n",
    "from spacy.lang.en import English\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-moderator",
   "metadata": {},
   "source": [
    "#### 1. Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grand-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jupyter/sb-entity-classification/data/data.csv')\n",
    "df.columns = ['class','name']\n",
    "\n",
    "# classes_list = pd.read_csv('/home/jupyter/sb-entity-classification/data/classes.txt', header = None)\n",
    "# classes_list['class'] = classes_list.index\n",
    "# classes_list.columns = ['class_name', 'class']\n",
    "# classes_list['class'] = classes_list['class'] + 1  # based on information provided in the brief\n",
    "\n",
    "# df = df.merge(classes_list, on = 'class', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-mandate",
   "metadata": {},
   "source": [
    "####  2. Train, Validation, Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "active-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "documented-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439029, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exceptional-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sample(frac = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smooth-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43903, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mature-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the split train, valid, and test set, for fair comparison between models\n",
    "# train.to_pickle('/home/jupyter/sb-entity-classification/data/train.pkl')\n",
    "# test.to_pickle('/home/jupyter/sb-entity-classification/data/test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-intensity",
   "metadata": {},
   "source": [
    "#### 3. Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-ending",
   "metadata": {},
   "source": [
    "##### 3.1. Simple statistical features already explored in EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frozen-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_statistical_features(df):\n",
    "    df_features = df.copy()\n",
    "\n",
    "    df_features['num_chars'] = df['name'].str.len()\n",
    "    df_features['num_words'] = df_features['name'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    count = lambda l1,l2: sum([1 for x in l1 if x in l2]) \n",
    "    df_features['num_punctuations']= df_features['name'].apply(lambda x: count(x,set(string.punctuation)))\n",
    "    df_features['num_ascii']= df_features['name'].apply(lambda x: count(x,set(string.ascii_letters)))\n",
    "    df_features['num_whitespace']= df_features['name'].apply(lambda x: count(x,set(string.whitespace)))\n",
    "    df_features['num_digits']= df_features['name'].apply(lambda x: count(x,set(string.digits)))\n",
    "    df_features['num_nonascii'] = df_features['num_chars']-df_features['num_punctuations']-df_features['num_digits']-df_features['num_ascii']- df_features['num_whitespace']\n",
    "    df_features = df_features.drop(['num_whitespace', 'num_ascii'], axis = 1)\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "public-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_statistical_features = create_statistical_features(train)\n",
    "all_cols = train_statistical_features.columns.tolist()\n",
    "statistical_feature_cols = [x for x in all_cols if x not in ['class', 'name']]\n",
    "train_statistical_features = train_statistical_features[statistical_feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-processing",
   "metadata": {},
   "source": [
    "##### 3.2 keyword in brackets also explored in EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "separated-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on common sense -\n",
    "hand_code_keywords = ['company']+['musician', 'singer', 'writer', 'artist', 'author']\\\n",
    "+ ['footballer', 'cricketer', 'football', 'baseball', 'rugby', 'hockey'] +\\\n",
    "['politician'] +['ship'] + ['crater', 'river'] + ['horse'] +['plant']\\\n",
    "+['album', 'EP', 'soundtrack'] +['film'] +['novel', 'magazine', 'book', 'journal', 'play', 'comics', 'newspaper', 'manga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "computational-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keyword_features(df):\n",
    "    df_features = df.copy()\n",
    "    df_features['within_brackets'] = df['name'].str.extract('.*\\((.*)\\).*')\n",
    "\n",
    "    df_features_with_brackets = df_features[['within_brackets']].dropna(axis = 0)\n",
    "    for keyword in hand_code_keywords:\n",
    "        df_features_with_brackets['has_{}'.format(keyword)] = df_features_with_brackets['within_brackets']\\\n",
    "                                                                .apply(lambda x: keyword in x.lower() )\n",
    "\n",
    "    df_features = df_features.drop('within_brackets', axis = 1)\n",
    "    df_features_with_brackets = df_features_with_brackets.drop('within_brackets', axis = 1)\n",
    "\n",
    "    df_features_with_brackets.replace({True:1, False:0}, inplace = True)\n",
    "    df_features = df_features.merge(df_features_with_brackets, left_index = True, right_index = True, how = 'left')\n",
    "    df_features.fillna(0, inplace = True)\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complete-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keyword_features = create_keyword_features(train)\n",
    "all_cols = train_keyword_features.columns.tolist()\n",
    "keyword_feature_cols = [x for x in all_cols if x not in ['class', 'name']]\n",
    "train_keyword_features = train_keyword_features[keyword_feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-delay",
   "metadata": {},
   "source": [
    "##### 3.3 NER explored in EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arabic-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "neither-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_features(df, NER_labels = None):\n",
    "    \n",
    "    df_features = df.copy()\n",
    "\n",
    "    df_features['NER_labels'] = df_features['name'].apply(lambda x: [i.label_ for i in nlp(x).ents])\n",
    "    df_features_NER = df_features[df_features['NER_labels'].apply(lambda x: len(x) !=0)][['NER_labels']]\n",
    "    \n",
    "    if NER_labels == None:\n",
    "        all_NER_labels = set(np.concatenate(df_features_NER['NER_labels'].tolist()))\n",
    "    else:\n",
    "        all_NER_labels = NER_labels\n",
    "        \n",
    "    for ner in all_NER_labels:\n",
    "        df_features_NER['ner_{}'.format(ner)] = df_features_NER['NER_labels'].apply(lambda x: ner in x )\n",
    "\n",
    "    df_features = df_features.drop('NER_labels', axis = 1)\n",
    "    df_features_NER = df_features_NER.drop('NER_labels', axis = 1)\n",
    "\n",
    "    df_features_NER.replace({True:1, False:0}, inplace = True)\n",
    "    df_features = df_features.merge(df_features_NER, left_index = True, right_index = True, how = 'left')\n",
    "    df_features.fillna(0, inplace = True)\n",
    "    \n",
    "    return df_features, all_NER_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "victorian-milan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 11s, sys: 113 ms, total: 4min 11s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ner_features, NER_labels_trained = create_ner_features(train)\n",
    "all_cols = train_ner_features.columns.tolist()\n",
    "ner_feature_cols = [x for x in all_cols if x not in ['class', 'name']]\n",
    "train_ner_features = train_ner_features[ner_feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-stupid",
   "metadata": {},
   "source": [
    "#### 4. Prepare feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optimum-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(train_keyword_features,left_index = True, right_index = True, how = 'left')\n",
    "#     train_statistical_features,left_index = True, right_index = True, how = 'left')\\\n",
    "# merge(train_keyword_features,left_index = True, right_index = True, how = 'left')\n",
    "    \n",
    "# .merge(train_ner_features,left_index = True, right_index = True, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lonely-edward",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['name','class'], axis = 1)\n",
    "y = train['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-toilet",
   "metadata": {},
   "source": [
    "#### 5. Train xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "inclusive-flush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:58:24] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=3, nthread=3, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(nthread = 3)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-remains",
   "metadata": {},
   "source": [
    "#### 6. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "healthy-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sample(frac = 0.1)\n",
    "\n",
    "# test_statistical_features = create_statistical_features(test)[statistical_feature_cols]\n",
    "test_keyword_features = create_keyword_features(test)[keyword_feature_cols]\n",
    "\n",
    "# test_ner_features, _ = create_ner_features(test, NER_labels_trained)\n",
    "# test_ner_features = test_ner_features[ner_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "increased-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test.merge(test_statistical_features,left_index = True, right_index = True, how = 'left')\\\n",
    "#             .merge(test_keyword_features,left_index = True, right_index = True, how = 'left')\\\n",
    "#             .merge(test_ner_features,left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "test = test.merge(test_keyword_features,left_index = True, right_index = True, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "magnetic-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exact-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['name','class'], axis = 1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "surprising-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_company</th>\n",
       "      <th>has_musician</th>\n",
       "      <th>has_singer</th>\n",
       "      <th>has_writer</th>\n",
       "      <th>has_artist</th>\n",
       "      <th>has_author</th>\n",
       "      <th>has_footballer</th>\n",
       "      <th>has_cricketer</th>\n",
       "      <th>has_football</th>\n",
       "      <th>has_baseball</th>\n",
       "      <th>...</th>\n",
       "      <th>has_soundtrack</th>\n",
       "      <th>has_film</th>\n",
       "      <th>has_novel</th>\n",
       "      <th>has_magazine</th>\n",
       "      <th>has_book</th>\n",
       "      <th>has_journal</th>\n",
       "      <th>has_play</th>\n",
       "      <th>has_comics</th>\n",
       "      <th>has_newspaper</th>\n",
       "      <th>has_manga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352650</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222332</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496922</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367108</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91103</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10976 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        has_company  has_musician  has_singer  has_writer  has_artist  \\\n",
       "151384          0.0           0.0         0.0         0.0         0.0   \n",
       "352650          0.0           0.0         0.0         0.0         0.0   \n",
       "453414          0.0           0.0         0.0         0.0         0.0   \n",
       "222332          0.0           0.0         0.0         0.0         0.0   \n",
       "496922          0.0           0.0         0.0         0.0         0.0   \n",
       "...             ...           ...         ...         ...         ...   \n",
       "211785          0.0           0.0         0.0         0.0         0.0   \n",
       "367108          0.0           0.0         0.0         0.0         0.0   \n",
       "91103           0.0           0.0         0.0         0.0         0.0   \n",
       "4533            0.0           0.0         0.0         0.0         0.0   \n",
       "173756          0.0           0.0         0.0         0.0         0.0   \n",
       "\n",
       "        has_author  has_footballer  has_cricketer  has_football  has_baseball  \\\n",
       "151384         0.0             0.0            0.0           0.0           0.0   \n",
       "352650         0.0             0.0            0.0           0.0           0.0   \n",
       "453414         0.0             0.0            0.0           0.0           0.0   \n",
       "222332         0.0             0.0            0.0           0.0           0.0   \n",
       "496922         0.0             0.0            0.0           0.0           0.0   \n",
       "...            ...             ...            ...           ...           ...   \n",
       "211785         0.0             0.0            0.0           0.0           0.0   \n",
       "367108         0.0             0.0            0.0           0.0           0.0   \n",
       "91103          0.0             0.0            0.0           0.0           0.0   \n",
       "4533           0.0             0.0            0.0           0.0           0.0   \n",
       "173756         0.0             0.0            0.0           0.0           0.0   \n",
       "\n",
       "        ...  has_soundtrack  has_film  has_novel  has_magazine  has_book  \\\n",
       "151384  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "352650  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "453414  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "222332  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "496922  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "...     ...             ...       ...        ...           ...       ...   \n",
       "211785  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "367108  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "91103   ...             0.0       0.0        0.0           0.0       0.0   \n",
       "4533    ...             0.0       0.0        0.0           0.0       0.0   \n",
       "173756  ...             0.0       0.0        0.0           0.0       0.0   \n",
       "\n",
       "        has_journal  has_play  has_comics  has_newspaper  has_manga  \n",
       "151384          0.0       0.0         0.0            0.0        0.0  \n",
       "352650          0.0       0.0         0.0            0.0        0.0  \n",
       "453414          0.0       0.0         0.0            0.0        0.0  \n",
       "222332          0.0       0.0         0.0            0.0        0.0  \n",
       "496922          0.0       0.0         0.0            0.0        0.0  \n",
       "...             ...       ...         ...            ...        ...  \n",
       "211785          0.0       0.0         0.0            0.0        0.0  \n",
       "367108          0.0       0.0         0.0            0.0        0.0  \n",
       "91103           0.0       0.0         0.0            0.0        0.0  \n",
       "4533            0.0       0.0         0.0            0.0        0.0  \n",
       "173756          0.0       0.0         0.0            0.0        0.0  \n",
       "\n",
       "[10976 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "classified-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "original-rabbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 14.91%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incorporate-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "invalid-discovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.889     0.010     0.020       785\n",
      "           2      0.000     0.000     0.000       815\n",
      "           3      1.000     0.066     0.123       807\n",
      "           4      1.000     0.093     0.171       814\n",
      "           5      1.000     0.064     0.120       829\n",
      "           6      0.750     0.004     0.007       805\n",
      "           7      0.000     0.000     0.000       748\n",
      "           8      0.963     0.060     0.114       862\n",
      "           9      0.000     0.000     0.000       818\n",
      "          10      1.000     0.006     0.013       782\n",
      "          11      0.079     1.000     0.146       796\n",
      "          12      1.000     0.323     0.488       805\n",
      "          13      1.000     0.313     0.476       755\n",
      "          14      0.940     0.169     0.287       555\n",
      "\n",
      "    accuracy                          0.149     10976\n",
      "   macro avg      0.687     0.151     0.140     10976\n",
      "weighted avg      0.684     0.149     0.136     10976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "elementary-northeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Company</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EducationalInstitution</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Artist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athlete</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OfficeHolder</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MeanOfTransportation</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Building</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaturalPlace</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Village</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Plant</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Album</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Film</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WrittenWork</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class_name  class\n",
       "0                  Company      1\n",
       "1   EducationalInstitution      2\n",
       "2                   Artist      3\n",
       "3                  Athlete      4\n",
       "4             OfficeHolder      5\n",
       "5     MeanOfTransportation      6\n",
       "6                 Building      7\n",
       "7             NaturalPlace      8\n",
       "8                  Village      9\n",
       "9                   Animal     10\n",
       "10                   Plant     11\n",
       "11                   Album     12\n",
       "12                    Film     13\n",
       "13             WrittenWork     14"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_list = pd.read_csv('/home/jupyter/sb-entity-classification/data/classes.txt', header = None)\n",
    "classes_list['class'] = classes_list.index\n",
    "classes_list.columns = ['class_name', 'class']\n",
    "classes_list['class'] = classes_list['class'] + 1  # based on information provided in the brief\n",
    "classes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-shannon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
